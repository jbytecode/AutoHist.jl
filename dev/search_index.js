var documenterSearchIndex = {"docs":
[{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/#Automatic-histogram-construction","page":"API","title":"Automatic histogram construction","text":"","category":"section"},{"location":"api/#AutoHist.histogram_irregular","page":"API","title":"AutoHist.histogram_irregular","text":"histogram_irregular(x::AbstractVector{<:Real}; rule::Str=\"bayes\", grid::String=\"regular\", right::Bool=true, greedy::Bool=true, maxbins::Int=-1, support::Tuple{Real,Real}=(-Inf,Inf), use_min_length::Bool=false, logprior::Function=k->0.0, a::Real=1.0)\n\nCreate an irregular histogram based on optimization of a criterion based on Bayesian probability, penalized likelihood or LOOCV. Returns a StatsBase.Histogram object with the optimal partition corresponding to the supplied rule.\n\nArguments\n\nx: 1D vector of data for which a histogram is to be constructed.\n\nKeyword arguments\n\nrule: The criterion used to determine the optimal number of bins. Defaults to the Bayesian method of Simensen et al. (2025).\ngrid: String indicating how the finest possible mesh should be constructed. Options are \"data\", which uses each unique data point as a grid point, \"regular\" (default) which constructs a fine regular grid, and \"quantile\" which constructs the grid based on the sample quantiles.\nright: Boolean indicating whether the drawn intervals should be right-inclusive or not. Defaults to true.\ngreedy: Boolean indicating whether or not the greedy binning strategy of Rozenholc et al. (2006) should be used prior to running the dynamical programming algorithm. Defaults to true. The algorithm can be quite slow for large datasets when this keyword is set to false.\nmaxbins: The maximal number of bins to be considered by the optimization criterion, only used if grid is set to \"regular\" or \"quantile\". Defaults to maxbins=min(4*n/log(n)^2, 1000). If the specified argument is not a positive integer, the default value is used.\nsupport: Tuple specifying the the support of the histogram estimate. If the first element is -Inf, then minimum(x) is taken as the leftmost cutpoint. Likewise, if the second elemen is Inf, then the rightmost cutpoint is maximum(x). Default value is (-Inf, Inf), which estimates the support of the data.\nuse_min_length: Boolean indicating whether or not to impose a restriction on the minimum bin length of the histogram. If set to true, the smallest allowed bin length is set to (maximum(x)-minimum(x))/n*log(n)^(1.5).\nlogprior: Unnormalized logprior distribution for the number k of bins. Defaults to a uniform prior. Only used in when rule=\"bayes\".\na: Dirichlet concentration parameter in the Bayesian irregular histogram model. Set to the default value (5.0) if the supplied value is not a positive real number. Only used when rule=\"bayes\".\n\nReturns\n\nH: StatsBase.Histogram object with weights corresponding to densities, e.g. :isdensity is set to true.\n\nExamples\n\njulia> x = [0.037, 0.208, 0.189, 0.656, 0.45, 0.846, 0.986, 0.751, 0.249, 0.447]\njulia> H1 = histogram_irregular(x)\njulia> H2 = histogram_irregular(x; grid=\"quantile\", support=(0.0, 1.0), logprior=k->-log(k), a=sqrt(10))\n\n...\n\n\n\n\n\n","category":"function"},{"location":"api/#AutoHist.histogram_regular","page":"API","title":"AutoHist.histogram_regular","text":"histogram_regular(x::AbstractVector{<:Real}; rule::Str=\"bayes\", right::Bool=true, maxbins::Int=1000, support::Tuple{Real,Real}=(-Inf,Inf), logprior::Function=k->0.0, a::Union{Real,Function}=1.0)\n\nCreate a regular histogram based on optimization criterion from Bayesian probability, penalized likelihood or LOOCV. Returns a StatsBase.Histogram object with regular bins, with the optimal bin number corresponding to the supplied criterion.\n\n...\n\nArguments\n\nx: 1D vector of data for which a histogram is to be constructed.\n\nKeyword arguments\n\nrule: The criterion used to determine the optimal number of bins. Defaults to the method Bayesian method of Simensen et al. (2025)\nright: Boolean indicating whether the drawn intervals should be right-inclusive or not. Defaults to true.\nmaxbins: The maximal number of bins to be considered by the optimization criterion. Ignored if the specified argument is not a positive integer. Defaults to maxbins=1000\nsupport: Tuple specifying the the support of the histogram estimate. If the first element is -Inf, then minimum(x) is taken as the leftmost cutpoint. Likewise, if the second element is Inf, then the rightmost cutpoint is maximum(x). Default value is (-Inf, Inf), which estimates the support of the data.\nlogprior: Unnormalized logprior distribution of the number k of bins. Only used in the case where the supplied rule is \"bayes\". Defaults to a uniform prior.\na: Specifies Dirichlet concentration parameter in the Bayesian histogram model. Can either be a fixed positive number or a function computing aₖ for different values of k. Defaults to 1.0 if not supplied. Uses default if suppled value is negative.\n\nReturns\n\nH: StatsBase.Histogram object with weights corresponding to densities, e.g. :isdensity is set to true.\n\nExamples\n\njulia> x = [0.037, 0.208, 0.189, 0.656, 0.45, 0.846, 0.986, 0.751, 0.249, 0.447]\njulia> H1 = histogram_regular(x)\njulia> H2 = histogram_regular(x; logprior=k->-log(k), a=k->0.5*k)\n\n...\n\n\n\n\n\n","category":"function"},{"location":"methods/#Supported-Methods","page":"Supported Methods","title":"Supported Methods","text":"","category":"section"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"Before we describe the methods included here in more detail, we introduce some notation. For ease of exposition, we present all methods covered here in the context of estimating the density of a sample x_1 x_2 ldots x_n on the unit interval, but note that extending the procedures presented here to other compact intervals. For some further background on histograms, we reccomend the excellent review by Birgé and Rozenholc (2006).","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"We let mathcalI = (mathcalI_1 mathcalI_2 ldots mathcalI_k) denote a partition of 01 into k intervals and write mathcalC for the length of an interval mathcalC. We can then write a histogram density estimate by","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"widehatf(x) = sum_j=1^k fracwidehattheta_jmathcalI_jmathbf1_mathcalI_j(x) quad xin 01","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"where mathbf1_mathcalI_j is the indicator function, widehattheta_j geq 0 for all j and sum_j=1^k widehattheta_j = 1.","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"For most of the methods considered here, the estimated bin probabilities are the maximum likelihood estimates widehattheta_j = N_jn, where N_j = sum_i=1^n mathbb1_mathcalI_j(x_i) is number of observations landing in interval mathcalI_j . The exception to this rule is the Bayesian approach of Simensen et al. (2025), which uses the Bayes estimator widehattheta_j = (5k + N_j)(5+n) instead.","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"The goal of an automatic histogram procedure is to find a partition mathcalI based on the sample alone which produces a reasonable density estimate. Regular histogram procedures only consider regular partitions, where all intervals in the partition are of equal length, so that one only needs to determine the number k of bins. Irregular histograms allow for partitions with intervals of unequal length, and try to determine both the number of bins and the locations of the cutpoints between the intervals. In all the irregular procedures covered here, we attempt to find best partition according to a criterion among all partitions with endpoints belonging to a given discrete mesh.","category":"page"},{"location":"methods/#Regular-histograms","page":"Supported Methods","title":"Regular histograms","text":"","category":"section"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"The following presents the selection criteria maximized by each keyword supported by the histogram_regular function. In each case the chosen value of k is understood to be the maximizer of the expression in question, and mathcalI = (mathcalI_1 mathcalI_2 ldots mathcalI_k) is the corresponding partition of 01 consisting of k equal-length bins.","category":"page"},{"location":"methods/#bayes:","page":"Supported Methods","title":"bayes:","text":"","category":"section"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"Consists of maximizing the log-marginal likelihood for given k,","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"   quad nlog (k) + sum_j=1^k biglog Gamma(a_j + N_j) - log Gamma(a_j)big + log p_n(k)","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"Here p_n(k) is the prior distribution on the number k of bins.","category":"page"},{"location":"methods/#aic-[Taylor-(1987)]:","page":"Supported Methods","title":"aic [Taylor (1987)]:","text":"","category":"section"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"Consists of maximizing a penalized log-likelihood,","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"    nlog (n) + sum_j=1^k N_j log (N_jn) - k","category":"page"},{"location":"methods/#bic-[Davies-et-al.-(2009)]:","page":"Supported Methods","title":"bic [Davies et al. (2009)]:","text":"","category":"section"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"Consists of maximizing a penalized log-likelihood,","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"    nlog (n) + sum_j=1^k N_j log (N_jn) - frack2log(n)","category":"page"},{"location":"methods/#br-[Birgé-and-Rozenholc-(2006)]:","page":"Supported Methods","title":"br [Birgé and Rozenholc (2006)]:","text":"","category":"section"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"Consists of maximizing a penalized log-likelihood,","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"    nlog (n) + sum_j=1^k N_j log (N_jn) - k - log^25(k)","category":"page"},{"location":"methods/#l2cv-[Rudemo-(1982)]:","page":"Supported Methods","title":"l2cv [Rudemo (1982)]:","text":"","category":"section"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"Consists of maximizing a L2 leave-one-out cross-validation criterion,","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"    -2k + kfracn+1n^2sum_j=1^k N_j^2","category":"page"},{"location":"methods/#klcv-[Hall-(1990)]:","page":"Supported Methods","title":"klcv [Hall (1990)]:","text":"","category":"section"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"Consists of maximizing a Kullback-Leibler leave-one-out cross-validation criterion,","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"    nlog(k) + sum_j=1^k N_jlog (N_j-1)","category":"page"},{"location":"methods/#mdl-[Hall-and-Hannan-(1988)]:","page":"Supported Methods","title":"mdl [Hall and Hannan (1988)]:","text":"","category":"section"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"Consists of finding the model providing the shortest encoding of the data, which is equivalent to maximization of","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"    nlog(k) + sum_j=1^k big(N_j-frac12big)logbig(N_j-frac12big) - big(n-frack2big)logbig(n-frack2big) - frack2log(n)","category":"page"},{"location":"methods/#References","page":"Supported Methods","title":"References","text":"","category":"section"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"Simensen, O. H., Christensen, D. & Hjort, N. L. (2025). Random Irregular Histograms. arXiv preprint. doi: 10.48550/ARXIV.2505.22034","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"Taylor, C. C. (1987). Akaike’s information criterion and the histogram. Biometrika. 74, 636–639. doi: 10.1093/biomet/74.3.636","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"Davies, P. L., Gather, U., Nordman, D., and Weinert, H. (2009). A comparison of automatic histogram constructions. ESAIM: Probability and Statistics, 13, 181–196. doi: 10.1051/ps:2008005.","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"Rozenholc, Y., Mildenberger, T., & Gather, U. (2010). Combining regular and irregular histograms by penalized likelihood. Computational Statistics & Data Analysis. 54, 3313–3323. doi: 10.1016/j.csda.2010.04.021","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"Birgé, L., & Rozenholc, Y. (2006). How many bins should be put in a regular histogram. ESAIM: Probability and Statistics. 10, 24–45. doi: 10.1051/ps:2006001","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"Rudemo, M. (1982). Empirical choice of histograms and kernel density estimators. Scandinavian Journal of Statistics. 9, 65-78","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"Hall, P. (1990). Akaike’s information criterion and Kullback–Leibler loss for histogram density estimation. Probability Theory and Related Fields. 85, 449–467. doi: 10.1007/BF01203164","category":"page"},{"location":"methods/","page":"Supported Methods","title":"Supported Methods","text":"Hall, P. and Hannan, E. J. (1988). On stochastic complexity and nonparametric density estimation. Biometrika. 75, 705–714. doi: 10.1093/biomet/75.4.705","category":"page"},{"location":"#AutoHist.jl-Documentation","page":"Introdution","title":"AutoHist.jl Documentation","text":"","category":"section"},{"location":"","page":"Introdution","title":"Introdution","text":"Fast automatic histogram construction. Supports a plethora of regular and irregular histogram procedures.","category":"page"},{"location":"#Quick-Start","page":"Introdution","title":"Quick Start","text":"","category":"section"},{"location":"","page":"Introdution","title":"Introdution","text":"The two main functions exported by this package are histogram_irregular and histogram_regular, which constructs an irregular or regular histogram with automatic selection of the number of bins based on the sample.","category":"page"},{"location":"","page":"Introdution","title":"Introdution","text":"julia> using AutoHist, Plots\njulia> x = randn(10^6);\njulia> H1 = histogram_regular(x);\njulia> plot(H1)\n\njulia> H2 = histogram_irregular(x);\njulia> plot(H2)","category":"page"},{"location":"#Supported-methods","page":"Introdution","title":"Supported methods","text":"","category":"section"},{"location":"","page":"Introdution","title":"Introdution","text":"Both the regular and the irregular procedure support a large number of criteria to select the histogram partition. The keyword argument rule controls the criterion used to choose the best partition, and includes the following criteria:","category":"page"},{"location":"","page":"Introdution","title":"Introdution","text":"Regular Histograms:\nRegular random histogram, \"bayes\" (default)\nL2 cross-validation, \"l2cv\"\nKullback-Leibler cross-validation: \"klcv\"\nAIC, \"aic\"\nBIC, \"bic\"\nBirgé and Rozenholc's criterion, \"br\"\nNormalized Maximum Likelihood, \"nml\"\nMinimum Description Length, \"mdl\"\nIrregular Histograms:\nIrregular random histogram, \"bayes\" (default)\nL2 cross-validation, \"l2cv\"\nKullback-Leibler cross-validation: \"klcv\"\nRozenholc et al. penalty R: \"penR\"\nRozenholc et al. penalty B: \"penB\"\nNormalized Maximum Likelihood: \"nml\"","category":"page"},{"location":"","page":"Introdution","title":"Introdution","text":"julia> histogram_irregular(x; rule=\"penR\")\njulia> histogram_regular(x; rule=\"aic\")","category":"page"},{"location":"","page":"Introdution","title":"Introdution","text":"WIP: Add another page where each method is described in greater detail.","category":"page"},{"location":"#Features","page":"Introdution","title":"Features","text":"","category":"section"},{"location":"","page":"Introdution","title":"Introdution","text":"In addition to providing automatic histogram construction, this library will at a later point in time include several convenience functions for histograms. These include functions to determine the number and the location of the modes of a histogram, and functions to compute numerical estimation error made with piecewise continuous densities in mind.","category":"page"}]
}
